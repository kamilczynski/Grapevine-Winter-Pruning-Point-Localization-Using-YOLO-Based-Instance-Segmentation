# PCA-Based Semantic Cut Line Extraction from YOLO Segmentation

This document provides the full mathematical formulation of the method used to
extract class-dependent semantic cut lines from YOLO polygon segmentation
annotations.

---

## 1. Problem Definition

Given:

- an RGB image  

The image is defined as:
$$
I \in \mathbb{R}^{H \times W \times 3}
$$

- a set of segmented objects represented as YOLO polygon annotations,

the goal is to extract, for each object, a semantically meaningful straight cut
line and its representative midpoint, suitable for downstream tasks such as:

- robotic manipulation,
- cutting or grasp planning,
- geometric measurement,
- alignment and inspection.

---

## 2. Input Representation

Each segmented object is represented by:

- a class label  
$$
c
$$

- a polygon defined by normalized coordinates  
$$
(\hat{x}_i, \hat{y}_i), \quad \hat{x}_i, \hat{y}_i \in [0,1]
$$

The normalized coordinates are mapped to image space as:

$$
x_i = \hat{x}_i W, \quad y_i = \hat{y}_i H
$$

forming a discrete polygon:

$$
\mathcal{P} = \{(x_i, y_i)\}_{i=1}^{N}
$$

---

## 3. Mask Generation and Contour Extraction

For each polygon $\mathcal{P}$, a binary mask is generated by rasterization.
From this mask, the external contour is extracted using full-resolution contour
tracing.

To ensure robustness against annotation artifacts:

- only the largest connected contour is retained,
- contours with insufficient point count are discarded.

---

## 4. Principal Axis Estimation (PCA)

To estimate the dominant geometric orientation of the object, Principal Component
Analysis (PCA) is applied to the contour points.

Let the contour centroid be defined as:

$$
\boldsymbol{\mu} = \frac{1}{K} \sum_{j=1}^{K} \mathbf{c}_j
$$

and the centered contour points as:

$$
\tilde{\mathbf{c}}_j = \mathbf{c}_j - \boldsymbol{\mu}
$$

Singular Value Decomposition is applied:

$$
\tilde{\mathbf{C}} = \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^\top
$$

where the first right-singular vector

$$
\mathbf{v}_1
$$

defines the principal axis of the object.

To guarantee consistent orientation across images, the axis direction is
stabilized relative to the image vertical coordinate.

---

## 5. Semantic Edge Selection

Contour points are projected onto the principal axis:

$$
s_j = \tilde{\mathbf{c}}_j^\top \mathbf{v}_1
$$

Semantic edge regions are selected using fixed percentile-based thresholds,
depending on the object class.

### Top edge (class 0)

$$
s_j \ge Q_{90}(s)
$$

### Bottom edge (class 1)

$$
s_j \le Q_{10}(s)
$$

If an insufficient number of contour points satisfies the selection criterion,
the object is discarded to avoid unstable geometric estimation.


---

## 6. Cut Line Estimation

A straight line is fitted to the selected edge points using orthogonal
(total least squares) regression.

The line is parametrized as:

$$
\mathbf{l}(t) = \mathbf{p}_0 + t \mathbf{v}
$$

where:

- $\mathbf{v}$ is the unit direction vector,
- $\mathbf{p}_0$ is a point on the line.

The finite line segment is obtained by projecting all edge points onto the
fitted line and selecting the extreme projections:

$$
t_{\min}, \; t_{\max}
$$

---

## 7. Representative Midpoint

The final geometric descriptor is defined as the midpoint of the fitted line
segment:

$$
\mathbf{m} = \frac{1}{2}
\left(
\mathbf{l}(t_{\min}) + \mathbf{l}(t_{\max})
\right)
$$

This point provides a stable, noise-resistant representation of the semantic cut
location.

---

## 8. Visualization and Output

For verification and analysis:

- segmentation contours,
- fitted cut lines,
- and midpoints

are rendered directly on the input image using class-specific color coding.

Annotated images can be exported without altering the original image resolution.
